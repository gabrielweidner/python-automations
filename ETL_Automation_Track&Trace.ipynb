{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d2a1232",
   "metadata": {},
   "source": [
    "## This project involves creating a delivery tracking spreadsheet that consolidates data from two different bases, along with outputs from merchandise dispatch and delivery scheduling sheets. The goal is to generate a comprehensive delivery tracking report that automatically updates through Power Query in Excel. Additionally, the data is uploaded to Power BI to create a transport performance dashboard for the company. This dashboard provides insights into delivery performance, efficiency, and other key metrics related to transport operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b603f4",
   "metadata": {},
   "source": [
    "## 0.0 IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deca1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import win32com.client\n",
    "from datetime import datetime,date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138db9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection with SAP\n",
    "\n",
    "SapGuiAuto = win32com.client.GetObject('SAPGUI')\n",
    "application = SapGuiAuto.GetScriptingEngine\n",
    "connection = application.Children(0)\n",
    "session = connection.Children(0)\n",
    "now = datetime.now()\n",
    "data_atual = date.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02235f9d",
   "metadata": {},
   "source": [
    "## 1.0 EXTRACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81895aca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extraction of base ZBRLE002N via SAP script\n",
    "session.findById(\"wnd[0]\").maximize()\n",
    "session.findById(\"wnd[0]/tbar[0]/okcd\").text = \"zbrle002n\"\n",
    "session.findById(\"wnd[0]\").sendVKey (0)\n",
    "session.findById(\"wnd[0]/tbar[1]/btn[17]\").press()\n",
    "session.findById(\"wnd[1]/usr/txtV-LOW\").text = \"LILIAN SILVA\"\n",
    "session.findById(\"wnd[1]/usr/txtENAME-LOW\").text = \"\"\n",
    "session.findById(\"wnd[1]/usr/txtV-LOW\").caretPosition = 12\n",
    "session.findById(\"wnd[1]/tbar[0]/btn[8]\").press()\n",
    "session.findById(\"wnd[0]/tbar[1]/btn[8]\").press()\n",
    "session.findById(\"wnd[0]/tbar[1]/btn[43]\").press()\n",
    "session.findById(\"wnd[1]/tbar[0]/btn[0]\").press()\n",
    "session.findById(\"wnd[1]/usr/ctxtDY_PATH\").text = \"C:/Users/30004761/OneDrive - DAVIDE CAMPARI MILANO S.P.A/Documentos/Gabriel/Extracoes ZBRLE002N\"\n",
    "session.findById(\"wnd[1]/usr/ctxtDY_FILENAME\").text = \"dt_prevista.xlsx\"\n",
    "session.findById(\"wnd[1]/usr/ctxtDY_FILENAME\").caretPosition = 16\n",
    "session.findById(\"wnd[1]/tbar[0]/btn[11]\").press()\n",
    "session.findById(\"wnd[0]/tbar[0]/btn[3]\").press()\n",
    "session.findById(\"wnd[0]/tbar[0]/btn[3]\").press()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d137b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extraction of base ZBRSD038 via SAP script\n",
    "session.findById(\"wnd[0]\").maximize()\n",
    "session.findById(\"wnd[0]/tbar[0]/okcd\").text = \"zbrsd038\"\n",
    "session.findById(\"wnd[0]\").sendVKey (0)\n",
    "session.findById(\"wnd[0]/tbar[1]/btn[17]\").press()\n",
    "session.findById(\"wnd[1]/usr/txtV-LOW\").text = \"OTIF\"\n",
    "session.findById(\"wnd[1]/usr/txtENAME-LOW\").text = \"\"\n",
    "session.findById(\"wnd[1]/usr/txtV-LOW\").caretPosition = 4\n",
    "session.findById(\"wnd[1]\").sendVKey (0)\n",
    "session.findById(\"wnd[1]/tbar[0]/btn[8]\").press()\n",
    "session.findById(\"wnd[0]/tbar[1]/btn[8]\").press()\n",
    "session.findById(\"wnd[0]/tbar[1]/btn[33]\").press()\n",
    "session.findById(\"wnd[1]/usr/subSUB_CONFIGURATION:SAPLSALV_CUL_LAYOUT_CHOOSE:0500/cntlD500_CONTAINER/shellcont/shell\").currentCellRow = 11\n",
    "session.findById(\"wnd[1]/usr/subSUB_CONFIGURATION:SAPLSALV_CUL_LAYOUT_CHOOSE:0500/cntlD500_CONTAINER/shellcont/shell\").selectedRows = \"11\"\n",
    "session.findById(\"wnd[1]/usr/subSUB_CONFIGURATION:SAPLSALV_CUL_LAYOUT_CHOOSE:0500/cntlD500_CONTAINER/shellcont/shell\").clickCurrentCell()\n",
    "session.findById(\"wnd[0]/mbar/menu[0]/menu[3]/menu[1]\").select()\n",
    "session.findById(\"wnd[1]/tbar[0]/btn[0]\").press()\n",
    "session.findById(\"wnd[1]/usr/ctxtDY_PATH\").text = \"C:/Users/30004761/OneDrive - DAVIDE CAMPARI MILANO S.P.A/Documentos/Gabriel/Extracoes ZBRLE002N\"\n",
    "session.findById(\"wnd[1]/usr/ctxtDY_FILENAME\").text = \"tta_new.xlsx\"\n",
    "session.findById(\"wnd[1]/usr/ctxtDY_FILENAME\").caretPosition = 12\n",
    "session.findById(\"wnd[1]/tbar[0]/btn[11]\").press()\n",
    "session.findById(\"wnd[0]/tbar[0]/btn[3]\").press()\n",
    "session.findById(\"wnd[0]/tbar[0]/btn[3]\").press()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814811d5",
   "metadata": {},
   "source": [
    "## 2.0 LOADING THE DATABASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60543f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "# Loading the extracted file 'dt_prevista'\n",
    "file_path_1 = 'Documentos/Extracoes ZBRLE002N/dt_prevista.xlsx'\n",
    "file_path_1 = 'Documentos/Extracoes ZBRLE002N/dt_prevista.xlsx'\n",
    "file_path_1 = os.path.abspath('Documentos/Extracoes ZBRLE002N/dt_prevista.xlsx')\n",
    "df_dt = pd.read_excel(file_path_1)\n",
    "\n",
    "# Loading the extracted file 'tta_new'\n",
    "file_path = 'Documentos/Extracoes ZBRLE002N/tta_new.xlsx'\n",
    "file_path = 'Documentos/Extracoes ZBRLE002N/tta_new.xlsx'\n",
    "file_path = os.path.abspath('Documentos/Extracoes ZBRLE002N/tta_new.xlsx')\n",
    "df_new = pd.read_excel(file_path, skiprows=0, header=0)\n",
    "\n",
    "# Path to the scheduling folder\n",
    "folder_path = 'Documentos/Planilhas Agendamento'\n",
    "# List of Excel files in the folder\n",
    "excel_files = glob.glob(folder_path + '/*.xlsx')\n",
    "# Empty list to store DataFrames for each spreadsheet\n",
    "df_list = []\n",
    "sheet_name = 'Agendamento '\n",
    "# Read the spreadsheets and add them to the df_list\n",
    "for file in excel_files:\n",
    "    df = pd.read_excel(file, sheet_name=sheet_name, skiprows=4, header=0)\n",
    "    df_list.append(df)\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "df_ag = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Load the files from the drive\n",
    "drive_br12 = 'export/br12.xlsx'\n",
    "drive_br12 = pd.read_excel(drive_br12)\n",
    "drive_br14 = 'export/br14.xlsx'\n",
    "drive_br14 = pd.read_excel(drive_br14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71689d",
   "metadata": {},
   "source": [
    "## 3.0 DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c65a5a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "df_new.rename(columns={'Documento de vendas':'Doc.venda','Número de nota fiscal eletrônica':'Nº NF-e','Número da remessa':'Número da remessa',\n",
    "                       'Referência cliente':'Ref.cliente','Emissor ordem':'TranspCli',\n",
    "                       'Razão Social do Cliente':'Razão Social do Cliente', 'Cidade do Cliente':'Cidade do Cliente',\n",
    "                       'Estado do Cliente':'Região', 'Peso Bruto.':' Peso total', 'Fator conversão':'Volume',\n",
    "                       'Itiner.transporte':'Cod. Rota', 'Nome da Transportadora':'Nome da Transportadora',\n",
    "                       'Nº transporte':'Transporte','Data de remessa':'Dt/Rem/Pr', 'Saída mercads.':'SaídaMerc',\n",
    "                       'Data de carregamento':'Dt/carreg/','Data do faturamento':'Dt/fatur/', 'InícAtualTransp':'Dt/Inc/Tr',\n",
    "                       'Data Entrega Informação':'Dt/Inform','Equipe de vendas':'Gr.Vend'},inplace=True)\n",
    "\n",
    "# Renaming columns\n",
    "df_dt.rename(columns={'Número de nota fiscal eletrônica':'Nº NF-e'},inplace=True)\n",
    "\n",
    "# Renaming columns for drive files\n",
    "drive_br12.rename(columns={'NF':'Nº NF-e'},inplace=True)\n",
    "drive_br14.rename(columns={'NF':'Nº NF-e'},inplace=True)\n",
    "drive_br12.rename(columns={'DELIVERY':'Delivery'},inplace=True)\n",
    "drive_br14.rename(columns={'DELIVERY':'Delivery'},inplace=True)\n",
    "\n",
    "# Renaming columns for drive files\n",
    "drive_br12.rename(columns={'DT EXPEDIÇÃO':'DT_EXP'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ea3ac44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Doc.venda', 'Nº NF-e', 'Número da remessa', 'Ref.cliente', 'TranspCli',\n",
       "       'Razão Social do Cliente', 'Cidade do Cliente', 'Região', ' Peso total',\n",
       "       'Volume', 'Cod. Rota', 'Nome da Transportadora', 'Transporte',\n",
       "       'Dt/Rem/Pr', 'SaídaMerc', 'Dt/carreg/', 'Dt/fatur/', 'Dt/Inc/Tr',\n",
       "       'Dt/Inform', 'Gr.Vend', 'Centro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c52b47b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping empty rows for 'Nº NF-e' and 'Delivery'\n",
    "df_new.dropna(subset=['Nº NF-e'], inplace=True)\n",
    "df_ag.dropna(subset=['Delivery'], inplace=True)\n",
    "\n",
    "# Converting to integer\n",
    "df_new['Nº NF-e'] = df_new['Nº NF-e'].astype(int)\n",
    "df_ag['Delivery'] = df_ag['Delivery'].astype(int)\n",
    "\n",
    "# Concatenating tables\n",
    "df_merged = pd.merge(df_new, df_dt[['Nº NF-e', 'Data Prevista']], on='Nº NF-e', how='left')\n",
    "df_merged.rename(columns={'Número da remessa':'Delivery'}, inplace=True)\n",
    "df_merged['Delivery'] = df_merged['Delivery'].astype(int)\n",
    "\n",
    "df_merged_2 = pd.merge(df_merged, df_ag[['Delivery', 'Data Agenda']], on='Delivery', how='left')\n",
    "\n",
    "df_merged_3 = pd.merge(df_merged_2, drive_br12[['Delivery', 'DT_EXP', 'TIPO VEICULO']], on='Delivery', how='left')\n",
    "df_merged_4 = pd.merge(df_merged_3, drive_br14[['Delivery', 'DT EXPEDIÇÃO', 'TIPO VEICULO', 'Horario Portaria', 'Data chegada veículo']], on='Delivery', how='left')\n",
    "\n",
    "df_merged_4['Data_Saída_Real'] = df_merged_4['DT_EXP'].fillna(df_merged_4['DT EXPEDIÇÃO'])\n",
    "df_merged_4 = df_merged_4.drop(['DT_EXP', 'DT EXPEDIÇÃO'], axis=1)\n",
    "df_merged_4['Tipo_Veículo'] = df_merged_4['TIPO VEICULO_x'].fillna(df_merged_4['TIPO VEICULO_y'])\n",
    "df_merged_4 = df_merged_4.drop(['TIPO VEICULO_x', 'TIPO VEICULO_y'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e7b3432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the column \"Nome da Transportadora\" exists in the DataFrame\n",
    "if \"Nome da Transportadora\" not in df_merged_4.columns:\n",
    "    df_merged_4[\"Nome da Transportadora\"] = \"\"\n",
    "\n",
    "# Apply lambda function with condition checking\n",
    "df_merged_4[\"Nome da Transportadora\"] = df_merged_4.apply(lambda x: \"ADM TRANSPORTS\" if (\n",
    "    \"Volume\" in x and  # Check if \"Volume\" is present in x\n",
    "    x[\"Volume\"] < 1000 and\n",
    "    x[\"Nome da Transportadora\"] == \"ABC DELIVERYS\" and\n",
    "    (x[\"Região\"] == \"MT\" or x[\"Região\"] == \"MS\")\n",
    ") else x[\"Nome da Transportadora\"], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adc32a1",
   "metadata": {},
   "source": [
    "## 4.0 EXPORT FINAL BASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed4743bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_4.drop_duplicates(subset=['Nº NF-e'], keep='first', inplace=True)\n",
    "df_merged_4.to_excel('Extracoes python/tt_atualizado.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
